<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.png"/>
	<link rel="shortcut icon" href="/img/logo_miccall.png">
	
			    <title>
    Hexo
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="miccall" />
    
    	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<meta name="generator" content="Hexo 5.4.0"></head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">MICCALL</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">分类</a>
	                    <ul class="submenu">
	                        <li>
	                        
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/about/" title="简历">
		                简历
		            </a>
		        </li>
		        
		        <li>
		            <a href="/group/" title="团队">
		                团队
		            </a>
		        </li>
		        
		        <li>
		            <a href="/gallery/" title="图库">
		                图库
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="标签">
		                标签
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/miccall" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
                    <li>
                        <a title="500px" href="http://500px.com" target="_blank" rel="noopener">
                            <i class="icon fa fa-500px"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url();background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 ></h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <hr>
<h2 id="Recommendation-system-amp-NLP"><a href="#Recommendation-system-amp-NLP" class="headerlink" title="Recommendation system &amp; NLP"></a>Recommendation system &amp; NLP</h2><p>图书推荐：《构建企业级推荐系统–算法工程实现与案例分析》</p>
<h1 id="从零开始搭建推荐系统"><a href="#从零开始搭建推荐系统" class="headerlink" title="从零开始搭建推荐系统"></a>从零开始搭建推荐系统</h1><p>考虑尽量快速让新的推荐业务上线，再逐步优化提升算法效果。不能一开始就想做出一个非常完美，效果非常好的推荐系统。在没有上线之前，我们只能根据个人经验来判断算法是否有效，但是个人经验判断往往有误，另外离线评估效果好的算法在真实业务场景中的就不一定提升商业化指标，即离线评估和在线评估可能不成正相关的(即使相关，有可能相关度也非常低)。<br>早期阶段缺乏用户与数据，计算成本低所以可以用单服务器部署推荐系统。当用户足够多、单机出现困难时再考虑利用Spark等分布式或计算平台重构现有业务逻辑。</p>
<h2 id="起步阶段产品的推荐-以金融新闻资讯等文本类产品为例"><a href="#起步阶段产品的推荐-以金融新闻资讯等文本类产品为例" class="headerlink" title="起步阶段产品的推荐(以金融新闻资讯等文本类产品为例):"></a>起步阶段产品的推荐(以金融新闻资讯等文本类产品为例):</h2><p>金融新闻资讯主要是文本标的物的产品，最简单的方式是基于TF-IDF模型来构建算法，每个文本基于TF-IDF构建向量表示，通过向量的余弦相似度来计算两个文本的相似度。<br>这种文本相似度可直接用于构建相关推荐(某个文章最相似的N个文章作为相似度推荐列表)。可将用户最近看的文章的向量进行加权(根据看的时间、停留时间等)，获得用户的向量表示，用户向量与文章向量的余弦就是用户对该文章的喜好度，还可以用item-based协同过滤的计算思路(如下公式)来计算用户对新文章的评分；还有一种方式就是先对文章进行聚类然，在推荐时，以推荐用户看过的文章所在类别的其他文章作为推荐列表。<br>$$sim(u,s) = \sum score(u,s_i)\times sim(s_i,s) $$<br>新闻资讯类一般可以做成信息流推荐，基于上面的TF-IDF算法也是可以实现实时推荐的。对于新发布的一篇文章，可以基于现有的词库(corpus)来生成该文章的向量表示(如果该新文章包含某些词不在词库中，可以直接忽略这些词，虽然会使精度有所下降，但是不用对文章重新求向量化，因此可以做到实时化，向量化的过程可以每天利用所有文章作为document重新训练一次)，向量化后，这个文章就可以其他文章一样处理了。</p>
<h2 id="矩阵分解推荐算法"><a href="#矩阵分解推荐算法" class="headerlink" title="矩阵分解推荐算法"></a>矩阵分解推荐算法</h2><p><strong>核心思想</strong><br>此处主要用显式反馈(用户的真实评分)来解释矩阵分解算法。其核心思想是将用户的评分矩阵$R$分解为两个矩阵$U$和$V$的乘积；某个用户对某个item的评分，就可以用矩阵U(用户的特征向量)对应的行和矩阵V对应的列(item的特征向量)的乘积（内积）。有了用户对item的评分就很容易为ta做推荐了。</p>
<p><strong>算法原理</strong><br>将矩阵分解转化为机器学习问题，假设所有用户有评分的(u,v)组成集合为A，u为用户，v为item，通过矩阵分解将用户u和标的物v嵌入k维隐式特征空间，$p_u$,$q_v$,那么用户u对v的预测评分为$\widehat{r_uv} = p_u $真实值和预测值之间的误差为$\Deltar = r_uv - r$预测的越准，$|\Deltar|越小。所以就等价转换为求最小值的优化问题了。</p>
<p><strong>求解方法</strong><br>利用SGD,ALS来求解。 </p>
<p><strong>拓展与优化</strong></p>
<ul>
<li>整合偏差项bias；</li>
<li>增加更多用户信息输入: 具体来说可以整合用户隐式反馈（收藏，点赞，分享等）和用户人口统计学信息（年龄，性别，地域，收入等）到矩阵分解模型中。最终整合了隐式反馈和人口统计学信息（包括偏差项）的用户预测公式可以写出最终优化目标函数，同样可以用SGD和ALS求解。</li>
<li>整合时间因素:前面的模型都是静态的，用户对item的喜好和评分，以及item的受欢迎程度可能会随着时间改变，所以引入$b_u (t)$ 来表示用户偏差随着时间改变，用包含时间的$b_v (t)$表示item随着时间变化而变化的趋势。</li>
<li>整合用户对评分的置信度：防止外界因素干扰，引入user对item喜欢的概率/置信率，操作越多、时间越长、付出越大，置信度越高，增加置信度因子$c_uv$,从而得到最终的优化函数。</li>
<li>隐式反馈</li>
<li>整合用户和标的物的metadata信息，该方法可以很好解决用户和标的物的冷启动问题。搜索引擎Lyst就用此方法,一个比较好的代码实现：<a target="_blank" rel="noopener" href="http://github.com/lyst/lightfm">http://github.com/lyst/lightfm</a><h2 id="近实时矩阵分解算法："><a href="#近实时矩阵分解算法：" class="headerlink" title="近实时矩阵分解算法："></a>近实时矩阵分解算法：</h2>前面的算法都适合做批处理，通过离线处理模型，再为用户推荐。批处理适合时效性要求不高的产品，比如电商或长视频。那么对时效性高的比如抖音，网抑云等短时间产生大量标的物的产品，需要实时的矩阵分解，对矩阵进行实时化改造，可以更快反映用户兴趣变化更快整合新标的物至推荐系统。推荐论文：<br>Yanxiang Huang, Bin Cui, Jie Jiang, Kunqian Hong, Wenyu Zhang, and Yiran Xie. 2016. Real-time Video Recommendation Exploration.  <a target="_blank" rel="noopener" href="https://doi.org/10.1145/2882903.2903743">https://doi.org/10.1145/2882903.2903743</a><br>Real-time top-n recommendation in social streams. <a target="_blank" rel="noopener" href="https://www.ismll.uni-hildesheim.de/pub/pdfs/Diaz_Drumond_et_al_RECSYS2012.pdf">https://www.ismll.uni-hildesheim.de/pub/pdfs/Diaz_Drumond_et_al_RECSYS2012.pdf</a><br>Online-Updating Regularized Kernel Matrix Factorization Models for Large-Scale Recommender Systems. <a target="_blank" rel="noopener" href="https://www.ismll.uni-hildesheim.de/pub/pdfs/Rendle2008-Online_Updating_Regularized_Kernel_Matrix_Factorization_Models.pdf">https://www.ismll.uni-hildesheim.de/pub/pdfs/Rendle2008-Online_Updating_Regularized_Kernel_Matrix_Factorization_Models.pdf</a><br>Fast incremental matrix factorization for recommendation with positive-only feedback. pdf: <a target="_blank" rel="noopener" href="https://asset-pdf.scinapse.io/prod/30495595/30495595.pdf">https://asset-pdf.scinapse.io/prod/30495595/30495595.pdf</a><br>Online Personalized Recommendation Based on Streaming Implicit User Feedback. <a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007%2F978-3-319-25255-1_59#aboutcontent">https://link.springer.com/chapter/10.1007%2F978-3-319-25255-1_59#aboutcontent</a></li>
</ul>
<h2 id="FM-因子分解机-Factorization-Machines-推荐算法原理"><a href="#FM-因子分解机-Factorization-Machines-推荐算法原理" class="headerlink" title="FM: 因子分解机(Factorization Machines)推荐算法原理"></a>FM: 因子分解机(Factorization Machines)推荐算法原理</h2><p>Paper link: <a target="_blank" rel="noopener" href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf">https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf</a><br>推导简单易懂的的一篇博文：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6370127.html">https://www.cnblogs.com/pinard/p/6370127.html</a><br>矩阵分解算法我们知道是一种高效的嵌入式方法，通过将用户和标的物嵌入低维向量空间，再利用用户和标的物的嵌入向量的内积来预测user对标的物的偏好得分。而FM的核心思想就来源于矩阵分解，MF可以看做是分解机FM的特例。</p>
<h3 id="FM简单介绍"><a href="#FM简单介绍" class="headerlink" title="FM简单介绍"></a>FM简单介绍</h3><p><em>FM是推荐系统工程师应该熟练掌握和应用的必备算法</em>。最早是2010年Rendel在ICDM提出，和传统线性模型不同的是，FM考虑了特征间的交叉，可对所有特征变量交互进行建模（类似svm的核函数），特征组合对于推荐系统是非常重要的，FM就体现了这个思想（主要是二姐特征组合），因此在推荐系统和计算广告领域关注的CTR点击率和CVR转化率有良好表现。</p>
<h4 id="从LR到SVM再到FM模型"><a href="#从LR到SVM再到FM模型" class="headerlink" title="从LR到SVM再到FM模型"></a>从LR到SVM再到FM模型</h4><h3 id="Some-FM-related-code"><a href="#Some-FM-related-code" class="headerlink" title="Some FM related code:"></a>Some FM related code:</h3><p><a target="_blank" rel="noopener" href="https://github.com/coreylynch/pyFM">https://github.com/coreylynch/pyFM</a><br>Factorization machines in python<br>857 stars</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Johnson0722/CTR_Prediction">https://github.com/Johnson0722/CTR_Prediction</a><br>CTR prediction using FM FFM and DeepFM<br>718 stars</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ibayer/fastFM">https://github.com/ibayer/fastFM</a><br>fastFM: A Library for Factorization Machines<br>945 stars</p>
<p><a target="_blank" rel="noopener" href="https://github.com/CastellanZhang/alphaFM">https://github.com/CastellanZhang/alphaFM</a><br>Multi-thread implementation of Factorization Machines with FTRL for binary-class classification problem.<br>666 stars</p>
<p><a target="_blank" rel="noopener" href="https://github.com/rixwew/pytorch-fm">https://github.com/rixwew/pytorch-fm</a><br>Factorization Machine models in PyTorch<br>604 stars</p>
<h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><p>Factorization machines in python<br>sklearn特征抽取API: sklearn.feature_extraction<br>字典特征抽取API: sklearn.feature_extrection.DictVectorizer<br>DictVectorizer处理对象是符号化（非数字化）、具有一定结构的数据，如字典等，将符号转化为one-hot表示。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">DictVectorizer(sparse = True,...)</span><br><span class="line">	DictVectorizer.fit_transform(x)</span><br><span class="line">	# x: 文本或者包含文本字符串的可迭代对象</span><br><span class="line">	#返回值：返回sparse矩阵</span><br><span class="line">	DictVectorizer.inverse_transform(x)</span><br><span class="line">	# x: array数组或者sparse矩阵</span><br><span class="line">	# 返回值：返回之前的数据格式</span><br><span class="line">	DictVectorizer.get_feature_names()</span><br><span class="line">	#返回值：单词列表</span><br><span class="line">	DictVectorizer.transform(x)</span><br><span class="line">	#按照原先的标准转换</span><br></pre></td></tr></table></figure>
<p>使用方法：<br>1.先实例化DictVectorizer<br>2.调取方法fit_transform(x)<br>3.DictVectorizer(sparse = False, …)输出数组形式。默认值为True时，返回的是sparse矩阵。</p>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Retrival O(tens of millions) to O(thousands)<br>Ranking O(thousands) to O(hundreds)<br>Post-ranking O(hundreds) to O(dozens)</p>
<p><strong>Content-based filtering &amp; collaborative filtering</strong><br>Building RS using SGD or WALS</p>
<h1 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">re.search(regex, string): to check if string contains regex, return contents regex.</span><br><span class="line">if sentence contains &#x27;。&#x27;, using string.split(&#x27;。&#x27;)</span><br><span class="line">some special usage:</span><br><span class="line">. == match any char</span><br><span class="line">^aaa == match all the items start with  aaa.</span><br><span class="line">aaa$ == match all the items end up with aaa.</span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>推荐知乎文章[NLP] 秒懂词向量Word2vec的本质：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26306795">https://zhuanlan.zhihu.com/p/26306795</a><br>材料阅读顺序：</p>
<ol>
<li><p>Mikolov 两篇原论文：<br>『Distributed Representations of Sentences and Documents』<br>   贡献：在前人基础上提出更精简的语言模型（language model）框架并用于生成词向量，这个框架就是 Word2vec<br>『Efficient estimation of word representations in vector space』<br>   贡献：专门讲训练 Word2vec 中的两个trick：hierarchical softmax 和 negative sampling<br>优点：Word2vec 开山之作，两篇论文均值得一读<br>缺点：只见树木，不见森林和树叶，读完不得要义。<br>   这里『森林』指 word2vec 模型的理论基础——即 以神经网络形式表示的语言模型<br>   『树叶』指具体的神经网络形式、理论推导、hierarchical softmax 的实现细节等等</p>
</li>
<li><p>北漂浪子的博客：『深度学习word2vec 笔记之基础篇』<br>优点：非常系统，结合源码剖析，语言平实易懂<br>缺点：太啰嗦，有点抓不住精髓</p>
</li>
<li><p>Yoav Goldberg 的论文：『word2vec Explained- Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method』<br>优点：对 negative-sampling 的公式推导非常完备<br>缺点：不够全面，而且都是公式，没有图示，略显干枯</p>
</li>
<li><p>Xin Rong 的论文：『word2vec Parameter Learning Explained』：<br>！重点推荐！<br>理论完备由浅入深非常好懂，且直击要害，既有 high-level 的 intuition 的解释，也有细节的推导过程<br>一定要看这篇paper！一定要看这篇paper！一定要看这篇paper！</p>
</li>
<li><p>来斯惟的博士论文『基于神经网络的词和文档语义向量表示方法研究』以及他的博客（网名：licstar）<br>可以作为更深入全面的扩展阅读，这里不仅仅有 word2vec，而是把词嵌入的所有主流方法通通梳理了一遍</p>
</li>
<li><p>几位大牛在知乎的回答：『word2vec 相比之前的 Word Embedding 方法好在什么地方？』<br>刘知远、邱锡鹏、李韶华等知名学者从不同角度发表对 Word2vec 的看法，非常值得一看</p>
</li>
<li><p>Sebastian 的博客：『On word embeddings - Part 2: Approximating the Softmax』<br>详细讲解了 softmax 的近似方法，Word2vec 的 hierarchical softmax 只是其中一种<br>机器之心– Word Embedding Papers | 经典再读之Word2Vec: <a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2020-06-15-6">https://www.jiqizhixin.com/articles/2020-06-15-6</a></p>
</li>
</ol>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-miccall-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://example.com/2021/10/21/recommendation_system/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://example.com/2021/10/21/recommendation_system/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-miccall-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a target="_blank" rel="noopener" href="http://miccall.tech " style="border-bottom: none;">miccall</a></li>
            </ul>
            
                <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
